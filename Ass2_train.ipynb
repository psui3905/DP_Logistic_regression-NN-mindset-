{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New_train.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/psui3905/DP_Logistic_regression-NN-mindset-/blob/master/Ass2_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_AtVyyFZ8L9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI_C95wacALX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF2cEfAO-Aqm",
        "colab_type": "code",
        "outputId": "f16b3146-c685-4607-ca51-17a2a9927a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "!git clone https://github.com/zhuqiangLu/deeplearning_dataset.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'deeplearning_dataset'...\n",
            "remote: Enumerating objects: 47446, done.\u001b[K\n",
            "remote: Total 47446 (delta 0), reused 0 (delta 0), pack-reused 47446\u001b[K\n",
            "Receiving objects: 100% (47446/47446), 1.86 GiB | 49.65 MiB/s, done.\n",
            "Resolving deltas: 100% (5/5), done.\n",
            "Checking out files: 100% (47444/47444), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vll4hIYi-HXM",
        "colab_type": "code",
        "outputId": "5ea4de58-37a2-4eca-89ee-25cb6caf95b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd deeplearning_dataset\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deeplearning_dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18mg5288oLTN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1296a90f-bf3b-4e07-99ee-42293a169f98"
      },
      "source": [
        "ls"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "README.md                                             \u001b[0m\u001b[01;34mtrain2014\u001b[0m/  train.txt\n",
            "resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5  train.csv   \u001b[01;34mval2014\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DFQfur--I3M",
        "colab_type": "code",
        "outputId": "aea66f5f-f3d8-4ffd-ed81-fc52cb509ff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ROOT = os.getcwd()\n",
        "\n",
        "NUM_CLASS = 20\n",
        "\n",
        "TRAIN_LABEL_FILE = 'train.txt' \n",
        "\n",
        "TRAIN_LABEL_CSV = 'train.csv'\n",
        "\n",
        "TRAIN_FILE = 'train2014'\n",
        "\n",
        "TRAIN_DATA_DIR = os.path.join(ROOT, TRAIN_FILE)\n",
        "\n",
        "PRETRAIN_WEIGHT = './resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "POOLING = 'max'\n",
        "\n",
        "ACTIVATION = 'sigmoid'\n",
        "\n",
        "\n",
        "METRICS = ['accuracy']\n",
        "\n",
        "TRAIN_RATIO = 0.8\n",
        "\n",
        "DEV_RATIO = 0.1\n",
        "\n",
        "TEST_RATIO = 0.1\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "EPOCH = 10\n",
        "\n",
        "IMAGE_SIZE = 300\n",
        "\n",
        "CLASSES=[]\n",
        "for i in range(NUM_CLASS):\n",
        "  CLASSES.append(str(i))\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "print(ROOT) #make sure you are under the deeplearning_dataset to access all data\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/deeplearning_dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUwUp2mK-OQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "txt_file = r\"train.txt\"\n",
        "csv_file = r\"train.csv\"\n",
        "\n",
        "# use 'with' if the program isn't going to immediately terminate\n",
        "# so you don't leave files open\n",
        "# the 'b' is necessary on Windows\n",
        "# it prevents \\x1a, Ctrl-z, from ending the stream prematurely\n",
        "# and also stops Python converting to / from different line terminators\n",
        "# On other platforms, it has no effect\n",
        "in_txt = csv.reader(open(txt_file, \"r\"), delimiter = '\\t')\n",
        "out_csv = csv.writer(open(csv_file, 'a'))\n",
        "first_row = ['filename', 'labels']\n",
        "out_csv.writerow(first_row)\n",
        "out_csv.writerows(in_txt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tcqg2xuB-QEV",
        "colab_type": "code",
        "outputId": "bafc7d2a-0f1b-4eee-87d2-23b3e8dfa516",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#split the labels by comma\n",
        "df = pd.read_csv(TRAIN_LABEL_CSV)\n",
        "df[\"labels\"]=df[\"labels\"].apply(lambda x:x.split(\",\"))\n",
        "\n",
        "#read labels\n",
        "with open(TRAIN_LABEL_FILE, 'r') as f:\n",
        "    labels = f.readlines()\n",
        "    \n",
        "#calculate the ratios\n",
        "train_size = int(len(labels) * TRAIN_RATIO)\n",
        "dev_size = int(len(labels) * DEV_RATIO)\n",
        "test_size = int(len(labels) * TEST_RATIO)\n",
        "\n",
        "\n",
        "#set up generators\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255.)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "#set up train generator\n",
        "train_generator= datagen.flow_from_dataframe( \n",
        "    dataframe= df[:train_size],\n",
        "    directory= TRAIN_DATA_DIR,\n",
        "    x_col= \"filename\",\n",
        "    y_col= \"labels\",\n",
        "    batch_size= BATCH_SIZE,\n",
        "    seed= 42,\n",
        "    shuffle= True,\n",
        "    class_mode= \"categorical\",\n",
        "    target_size= (IMAGE_SIZE,IMAGE_SIZE))\n",
        "\n",
        "#set up dev generator\n",
        "valid_generator=test_datagen.flow_from_dataframe(\n",
        "    dataframe=df[train_size:(train_size + dev_size) ],\n",
        "    directory= TRAIN_DATA_DIR,\n",
        "    x_col= \"filename\",\n",
        "    y_col= \"labels\",\n",
        "    batch_size= BATCH_SIZE,\n",
        "    seed= 42,\n",
        "    shuffle= True,\n",
        "    class_mode= \"categorical\",\n",
        "    target_size= (IMAGE_SIZE,IMAGE_SIZE))\n",
        "\n",
        "#set up test\n",
        "test_generator=test_datagen.flow_from_dataframe(\n",
        "    dataframe=df[(train_size + dev_size): ],\n",
        "    directory= TRAIN_DATA_DIR,\n",
        "    x_col= \"filename\",\n",
        "    batch_size= 1,\n",
        "    seed= 42,\n",
        "    shuffle= False,\n",
        "    class_mode= None,\n",
        "    target_size= (IMAGE_SIZE,IMAGE_SIZE))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#get pretrain weights\n",
        "weights = PRETRAIN_WEIGHT"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 25540 images belonging to 20 classes.\n",
            "Found 3192 images belonging to 20 classes.\n",
            "Found 3009 images.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzFtvylG-Toi",
        "colab_type": "code",
        "outputId": "6a004c08-be46-40fa-b180-15fd23d08b62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#define base model\n",
        "#model = Sequential()\n",
        "\n",
        "# 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "# NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\n",
        "model = Sequential()\n",
        "base_model  = (applications.ResNet50(include_top = False,  pooling = POOLING, weights = weights))\n",
        "\n",
        "model.add(base_model)\n",
        "#freeze the pretrained model\n",
        "model.add(Dense(2048, activation = 'relu'))\n",
        "model.add(Dropout(rate = 0.5))\n",
        "model.add(Dense(512, activation = 'relu'))\n",
        "model.add(Dropout(rate = 0.5))\n",
        "model.add(Dense(20, activation = 'sigmoid'))\n",
        "\n",
        "model.layers[0].trainable = False\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1gY_Dtg4FZs",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mO119Dn5-VvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvgHnORt-YvJ",
        "colab_type": "code",
        "outputId": "1099b3cd-bd7c-41a5-a433-3a4153180578",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "def arg(y_true,y_pred):\n",
        "  return K.cast(K.equal(K.argmax(y_true, axis=-1),\n",
        "                          K.argmax(y_pred, axis=-1)),\n",
        "                  K.floatx())\n",
        "\n",
        "#optimizer\n",
        "opt = optimizers.RMSprop(lr = 0.0001)\n",
        "model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy', arg])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 2048)              23587712  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 20)                10260     \n",
            "=================================================================\n",
            "Total params: 28,843,412\n",
            "Trainable params: 5,255,700\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgUJsZ2T-bgr",
        "colab_type": "code",
        "outputId": "f9f26acc-e0df-4b3e-c81c-9ec92f271ab3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(EPOCH)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iz1CD46-fV6",
        "colab_type": "code",
        "outputId": "342b2d6d-c840-4f8a-a9f5-e639dc0bddc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "\n",
        "model.fit_generator(train_generator, \n",
        "                    steps_per_epoch = train_size//BATCH_SIZE,\n",
        "                    validation_data = valid_generator,\n",
        "                    validation_steps= dev_size//BATCH_SIZE,\n",
        "                    epochs = EPOCH,\n",
        "                    verbose = 1\n",
        "                   )\n",
        "\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.1508 - acc: 0.9549 - arg: 0.5811\n",
            "799/799 [==============================] - 208s 261ms/step - loss: 0.1374 - acc: 0.9521 - arg: 0.5350 - val_loss: 0.1508 - val_acc: 0.9549 - val_arg: 0.5811\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.1499 - acc: 0.9542 - arg: 0.5899\n",
            "799/799 [==============================] - 207s 260ms/step - loss: 0.1369 - acc: 0.9524 - arg: 0.5347 - val_loss: 0.1499 - val_acc: 0.9542 - val_arg: 0.5899\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.1530 - acc: 0.9557 - arg: 0.5990\n",
            "799/799 [==============================] - 208s 260ms/step - loss: 0.1357 - acc: 0.9527 - arg: 0.5431 - val_loss: 0.1530 - val_acc: 0.9557 - val_arg: 0.5990\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.1503 - acc: 0.9552 - arg: 0.5811\n",
            "799/799 [==============================] - 208s 260ms/step - loss: 0.1351 - acc: 0.9529 - arg: 0.5477 - val_loss: 0.1503 - val_acc: 0.9552 - val_arg: 0.5811\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.1483 - acc: 0.9548 - arg: 0.5802\n",
            "799/799 [==============================] - 207s 260ms/step - loss: 0.1346 - acc: 0.9533 - arg: 0.5499 - val_loss: 0.1483 - val_acc: 0.9548 - val_arg: 0.5802\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.1406 - acc: 0.9552 - arg: 0.5736\n",
            "799/799 [==============================] - 208s 260ms/step - loss: 0.1347 - acc: 0.9539 - arg: 0.5497 - val_loss: 0.1406 - val_acc: 0.9552 - val_arg: 0.5736\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.1523 - acc: 0.9553 - arg: 0.5915\n",
            "799/799 [==============================] - 207s 259ms/step - loss: 0.1341 - acc: 0.9541 - arg: 0.5547 - val_loss: 0.1523 - val_acc: 0.9553 - val_arg: 0.5915\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 22s 215ms/step - loss: 0.1422 - acc: 0.9560 - arg: 0.5818\n",
            "799/799 [==============================] - 207s 259ms/step - loss: 0.1331 - acc: 0.9543 - arg: 0.5575 - val_loss: 0.1422 - val_acc: 0.9560 - val_arg: 0.5818\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 22s 218ms/step - loss: 0.1394 - acc: 0.9562 - arg: 0.5846\n",
            "799/799 [==============================] - 208s 260ms/step - loss: 0.1327 - acc: 0.9542 - arg: 0.5575 - val_loss: 0.1394 - val_acc: 0.9562 - val_arg: 0.5846\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.1452 - acc: 0.9560 - arg: 0.5843\n",
            "799/799 [==============================] - 207s 259ms/step - loss: 0.1324 - acc: 0.9544 - arg: 0.5563 - val_loss: 0.1452 - val_acc: 0.9560 - val_arg: 0.5843\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f96569389b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxdcanDG9lJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model.save('my_model.h5')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PT9xmMIX-hTB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd9091f8-06fc-4b68-9acf-9839dbc20f8c"
      },
      "source": [
        "test_generator.reset()\n",
        "pred=model.predict_generator(test_generator,\n",
        "steps=test_generator.n//test_generator.batch_size,\n",
        "verbose=1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3009/3009 [==============================] - 56s 19ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O697-8xZ-j5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = np.array(pred)\n",
        "am = np.argmax(pred, axis = -1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNt3N2b6-msG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "87a1ad20-7064-4d58-ccb3-85e96c6dfd54"
      },
      "source": [
        "print(pred)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.14032626e-03 8.31484795e-06 0.00000000e+00 ... 0.00000000e+00\n",
            "  0.00000000e+00 2.08199024e-04]\n",
            " [2.57434845e-02 7.41985440e-03 6.13409281e-03 ... 2.31352448e-03\n",
            "  6.35403395e-03 1.41161293e-01]\n",
            " [4.57358062e-02 9.76929069e-03 2.53221095e-01 ... 2.82343268e-01\n",
            "  2.97113538e-01 4.80715871e-01]\n",
            " ...\n",
            " [1.00134194e-01 1.69914097e-01 4.70742583e-03 ... 8.47044587e-03\n",
            "  2.57810652e-02 1.37428969e-01]\n",
            " [3.04579735e-05 2.98023224e-08 5.03957272e-05 ... 5.47147393e-01\n",
            "  4.84250486e-01 1.30443186e-01]\n",
            " [7.84923732e-02 2.81339884e-02 3.32520306e-02 ... 7.73268938e-02\n",
            "  1.11506283e-01 3.86135161e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0I176Wk-oHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "pred_bool = (pred > 0.5)\n",
        "predictions=[]\n",
        "labels = train_generator.class_indices\n",
        "\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "for row in pred_bool:\n",
        "    l=[]\n",
        "    for index,cls in enumerate(row):\n",
        "        if cls:\n",
        "            l.append(labels[index])\n",
        "    predictions.append(\",\".join(l))\n",
        "filenames=test_generator.filenames\n",
        "results=pd.DataFrame({\"Filename\":filenames,\n",
        "                      \"Predictions\":predictions})\n",
        "results.to_csv(\"results.csv\",index= False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfBGPinZyyNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions=[]\n",
        "labels = train_generator.class_indices\n",
        "\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "for i in am:\n",
        "  predictions.append(labels[i])\n",
        "  \n",
        "filenames=test_generator.filenames\n",
        "results=pd.DataFrame({\"Filename\":filenames,\n",
        "                      \"Predictions\":predictions})\n",
        "results.to_csv(\"results_2.csv\",index= False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mibMVy_hzkuo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5adea502-05f6-4a8f-bfd7-7869d09796d0"
      },
      "source": [
        "test_labels = df['labels'][(train_size + dev_size):].values\n",
        "\n",
        "t = 0\n",
        "for i in range(len(predictions)):\n",
        "  if predictions[i] in test_labels[i]:\n",
        "    t+=1\n",
        "print(t/len(predictions));"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6706547025589897\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00kCyub_1K-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}